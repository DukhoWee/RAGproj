KAIST 전기 및 전자공학부 Co-op 프로그램 학생 소개서

1. 지원기업(부서) : KC-ML2
2. Co-op기간(현장실습 기간) :

2025.09.01~2026.02.27(6개월간)

3. 인적사항
성명:

위덕호

이메일: wdhdh3@kaist.ac.kr
핸드폰번호: 010-4529-2404

4. 학력사항:
총 이수 학점(*현재 수강중인 과목 포함): 110 학점
총 재학 학기(현재 학기포함) : 7학기

5. 전공 이수 과목(*현재 수강중인 과목 포함)
전자과 전공 과목:
EE201 회로이론 / EE202 신호 및 시스템 / EE209 전자공학을 위한 프로그래밍 / EE210 확률과 기초 확률과정 /
EE305 전자설계 및 실험
EE211 물리전자개론 / EE303 디지털시스템 / EE304 전자회로 / EE331 기계학습개론 / EE362 반도체소자 / EE381
제어시스템공학 / EE485 전자공학특강 I<EE안의 내 삶과 진로 I> / EE485 전자공학특강 I<최신 소프트웨어 개발
환경 및 도구 연습> / EE531 통계적 학습이론 / EE581 선형시스템 / EE495 개별연구(유창동 교수님) / EE495 개별
연구 (유창동 교수님)
전산과 전공 과목:
CS204 이산구조 / CS206 데이타구조 / CS230 시스템프로그래밍 / CS320 프로그래밍언어 / CS360 데이타베이스
개론
6. 실무관련 경력 (예: 프로그래밍, 회로 설계, 시스템 설계 등)
없습니다.

7. 개별연구 이수 내용:
유창동 교수님의 U-AIM 연구실에서 이번 학기 포함 2학기 동안 개별연구를 이수하였습니다. 이 기간 동안
“Attention Is All You Need”, “Training language models to follow instructions with human feedback” 등 LLM 관련
주요 논문 리뷰 및 발표를 통해 이론적인 기반을 다졌습니다. 또한 Hugging Face의 TRL 라이브러리를 활용하여
SFT(Supervised Fine-Tuning)와 DPO(Direct Preference Optimization) 방식으로 LLM을 직접 학습시키는 실습을 진
행하며, LLM의 학습 구조와 세부 과정에 대한 이해를 심화할 수 있었습니다.

<지원동기>
저는 학부 과정에서 기계학습개론 수업을 수강하며 인공지능에 깊은 관심을 두게 되었고, 그중에서도 가장 높은 활용성
을 보이는 인공지능인 대규모 언어 모델(LLM)에 매력을 느끼게 되었습니다. 특히, QA, 번역, 요약 등 다양한 태스크를 하나
의 모델로 처리할 수 있다는 점이 매우 흥미로웠습니다. 이에 개별연구나 통계적 학습 이론 등의 관련 수업을 통해 LLM과
기계학습 전반에 대한 이론과 구현을 학습해 왔습니다.
그러나 학문적 접근만으로는 LLM이 실제 산업 현장에서 어떤 문제를 해결하는 데 사용되고, 어떤 방식으로 운영 및 개
선되는지를 체감하기 어려웠습니다. 특히, 기업에서의 LLM은 단순한 연구를 넘어 사용 환경, 데이터 파이프라인, 성능 개
선, 시스템 구조 등 다양한 요소들과 맞물려 돌아간다고 알고 있습니다. 이러한 복잡한 활용 사례를 직접 보고 배우고자 학
부생 신분으로 실무 경험을 쌓을 수 있는 EE Co-op, 그 중에서도 LLM 관련 연구를 수행하는 KC-ML2에서 실무 경험을
쌓고자 지원하게 되었습니다.
또한 ML2 블로그의 졸업생 인터뷰(KAIST EE Co-op 편)를 읽으며, 자율적인 연구 환경 속에서 관심 있는 주제를 발전시키
고 연구자로서 필요한 자질을 키울 수 있다는 점이 인상 깊었고, 제가 지향하는 성장 방향과 잘 맞는다고 느꼈습니다. 다양
한 과목을 병행하는 학기 중과 달리, ML2에서의 EE Co-op은 하나의 주제에 몰입할 수 있는 환경이라는 점에서도, 관심 분
야에 깊이 파고들 좋은 기회가 될 것이라 확신합니다.

<자기소개(본인의 강점/장점, 관심 분야, 과거 이수과목 중 관심 과목 등을 자유롭게 기술)>
저는 소통을 즐기고, 다른 사람의 의견을 경청하는 데 능숙합니다. 평소에도 친구들과 특정 주제를 정해 깊이 있는 대화
를 나누는 것을 좋아합니다. 단순한 일상 대화가 아니라, 사회적 이슈나 기술, 철학 등 다양한 주제에 대해 서로의 관점을
공유하고 토론하면서 생각의 폭을 넓히는 데 큰 즐거움을 느낍니다. 이러한 과정에서 상대방의 의견을 주의 깊게 듣고, 그
에 공감하거나 비판적으로 사고하며 제 생각을 조리 있게 표현하는 능력을 자연스럽게 키워왔습니다. 이러한 소통 방식은
단순히 말하는 기술을 넘어서, 상대방을 존중하는 태도와 논리적인 의사 전달 능력을 기르는 데 도움이 되었다고 생각합니
다. 이에 저는 소통과 협업에 있어서 긍정적인 역할을 해낼 수 있다고 자신합니다.
또한 저는 평소 상상하는 것을 좋아하고, 다양한 가능성을 떠올리는 데 강점을 가지고 있습니다. 사소한 아이디어라도 흘
려보내지 않고, 연구에 적용할 수 있을지 고민해 보는 편입니다. 예를 들어, 한글의 풀어쓰기를 활용한 숫자 야구형 퍼즐인
꼬들을 LLM이 해결할 수 있을지 궁금하여 직접 실험해 본 적이 있습니다. 꼬들의 원조이자 영어 기반 퍼즐인 Wordle은 잘
해결하는 반면, 꼬들에 대해서는 어려움을 겪는 것을 확인하였습니다. 저는 이런 현상의 원인이 LLM이 한글 풀어쓰기 구조
를 학습하지 못했기 때문이라고 판단했고, 이를 개선하기 위한 실험적 프로젝트를 진행 중입니다. 현재 한글 풀어쓰기 구조
를 추가로 학습시킨다면, 성능이 개선되는지를 실험하고 있습니다. 이처럼 저는 작은 아이디어라도 탐구로 연결하고, 실험
과 관찰을 통해 그 가능성을 검증하려 노력합니다.
상상력을 실천으로 옮기기 위해서는 탄탄한 배경 지식이 필수적이라고 생각합니다. 아이디어를 구체화하고 실현하려면,
이를 뒷받침할 이론적 기반이 필요하기 때문입니다. 그런 점에서 학부 과정에서 가장 인상 깊게 들은 과목은 현재 수강 중
인 “통계적 학습이론”입니다. 이 과목을 수강하기 이전에는 머신 러닝과 인공지능을 주로 직관에 기반해 이해하는 수준이었
습니다. 그러나 수업을 통해 VC dimension, PAC Learning 등 머신 러닝의 이론적 배경에 대해 체계적으로 배우며 그동안 감
각적으로만 알던 개념들이 수학적으로 정리되어 깊이 있는 이해로 확장되었습니다.
저는 상상력과 이를 실천으로 옮기는 태도, 그리고 원활한 소통을 바탕으로 연구와 실무에서 의미 있는 기여를 할 수 있
다고 확신합니다.

끝.
